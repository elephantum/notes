31 октября произошел релиз Gateway API v1.0 для Kubernetes. У нас под управлением находится много кластеров, поэтому любые изменения в этой области для нас релевантны.

Gateway API предназначен решать задачу доступа снаружи ко внутренним сервисам, развернутым в Kubernetes кластере. Примерно так же звучит и описание Ingress API. В чем фишка и чем отличается от предыдущего способа?

Наш любимый Kubernetes-провайдер - это Google. И в области работы с Ingress в Google есть некоторые нюансы.

В базе при использовании GKE есть два подхода к Ingress: 
* стандартный GKE способ, который транслируется на крутейшую гугл-инфраструктуру Load Balancer-ов
* и более дешевый: использование Ingress-как-приложения внутри кластера, например `ingress-nginx`

Для любого высоконагруженного или чувствительного сервиса использовать `ingress-nginx` не хочется: мало ли он не выдержит нагрузку или что-то пойдет не так другим способом. Поэтому хочется приложиться к идеальному решению GCP LB.

Но нативные Ingress в GKE очень дорогие при активном использовании. Почему? Потому что из-за специфики структуры ресурса Ingress и его отображения на ресурсы гугла, каждый отдельный ингресс приводил к созданию связки: публичный IP + LB (примерная стоимость такой связки $20/мес). То есть если вы выставляете 10 сервисов наружу на каких-то доменных именах, то в инфраструктуре возникает 10 отдельных публичных IP и 10 отдельных Load Balancer-ов. И эта конструкция становится чувствительной с точки зрения биллинга GCP.

Очевидно, что все это не очень эффективно и 10 сервисов спокойно могли бы жить на одном публичном IP, который обслуживает один 

---
А может быть я и не прав. Потому что Forwarding rules возникают как в случае Ingress так и в случае Gateway одинаково